{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e93100-d0d5-4c9c-a633-982a0f38c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032ed2d-ee33-411b-8e8e-856690563a2c",
   "metadata": {},
   "source": [
    "###Basic Generating Restaurant name using lang chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6be2f9-6f59-4639-ad60-1d35d3b75565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Maharaja's Palace\n",
      "2. Spice Symphony\n",
      "3. Saffron Garden\n",
      "4. Royal Tandoor\n",
      "5. Masala Magic\n",
      "6. Curry Kingdom\n",
      "7. The Taj Mahal\n",
      "8. Namaste India\n",
      "9. Bollywood Bites\n",
      "10. Flavors of India\n",
      "11. Chai and Chaat\n",
      "12. The Great Indian Feast\n",
      "13. Tandoori Nights\n",
      "14. The Royal Spice\n",
      "15. Curry House \n"
     ]
    }
   ],
   "source": [
    "os.environ['OPENAI_API_KEY']='USe your OPENAI API KEY'\n",
    "llm = OpenAI(temperature=0.6) \n",
    "name=llm(\"I want to open a fancy indian restaurant can you suggest me a nice name\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b2222-3a9a-4baf-9935-762364ab17c6",
   "metadata": {},
   "source": [
    "#####Creating template for generating different name for different type of cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38c466c-e9e5-466c-8138-e1b97a402476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Indian food. suggest a fancy name for this.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. suggest a fancy name for this.\"\n",
    ")\n",
    "name.format(cuisine=\"Indian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1856fdf-c136-4045-b89c-514dbb9dade5",
   "metadata": {},
   "source": [
    "###Creating single chain for a single prompt to generate the name of a restaurant based on cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ea2e6f-eae4-4054-90ec-abb7f15ae8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Dragon\\'s Palace\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm, prompt=name)\n",
    "chain.run(\"chinese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a796bf-18fb-4b1f-b52e-2dfaed73a70d",
   "metadata": {},
   "source": [
    "### Tried to create 2 chains prompting the name for a restaurant and menu items it should have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac207f3-468d-451b-971f-2228d4d94abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6) \n",
    "name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain=LLMChain(llm=llm, prompt=name)\n",
    "\n",
    "items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"suggest some menu items for r{estaurant_name}. Return it as comma seprated list.\"\n",
    ")\n",
    "food_items=LLMChain(llm=llm,prompt=items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07dafe-7455-41d1-8b8e-9ec180179c80",
   "metadata": {},
   "source": [
    "####For merging 2 or more chains there are many different functions i have tried 2 functions\n",
    "1.Simple Sequential chain\n",
    "2.Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c352b4c0-73cb-423e-aa13-0266c68d86ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Caprese Salad: Fresh mozzarella, tomatoes, and basil drizzled with balsamic glaze\\n2. Fettuccine Alfredo: Creamy alfredo sauce served over homemade fettuccine\\n3. Chicken Parmigiana: Breaded chicken breast topped with marinara sauce and melted mozzarella cheese\\n4. Seafood Linguine: Shrimp, scallops, and clams tossed in a white wine garlic sauce\\n5. Eggplant Parmigiana: Breaded eggplant topped with marinara sauce and melted mozzarella cheese\\n6. Lasagna Bolognese: Layers of homemade pasta, beef ragu, and creamy béchamel sauce\\n7. Gnocchi Pesto: Potato dumplings in a creamy pesto sauce with cherry tomatoes and pine nuts\\n8. Shrimp Scampi: Sautéed shrimp in a garlic butter sauce served over linguine\\n9. Chicken Marsala: Sautéed chicken breast in a marsala wine sauce with mushrooms\\n10. Tiramisu: Classic Italian dessert made with ladyfingers, mascarpone cheese, and espresso.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=SimpleSequentialChain(chains=[name_chain,food_items])\n",
    "chain.run(\"Italian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a7231-60f4-4a75-b503-39d0ac0f548b",
   "metadata": {},
   "source": [
    "####Method 2 Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26e6bda-497c-4923-b558-e0d06c9a76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6) \n",
    "name=PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain=LLMChain(llm=llm, prompt=name, output_key=\"name\")\n",
    "\n",
    "items=PromptTemplate(\n",
    "    input_variables=['name'],\n",
    "    template=\"suggest some menu items for {name}. Return it as comma seprated list.\"\n",
    ")\n",
    "food_items=LLMChain(llm=llm,prompt=items,output_key=\"Menu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b786811c-97ad-444d-96cd-dae1097a0ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Indian',\n",
       " 'name': '\\n\\n\"Spice Palace\" ',\n",
       " 'Menu': '\\n\\n1. Tandoori Chicken\\n2. Butter Chicken\\n3. Lamb Vindaloo\\n4. Vegetable Samosas\\n5. Chicken Tikka Masala\\n6. Palak Paneer\\n7. Chana Masala\\n8. Biryani\\n9. Garlic Naan\\n10. Mango Lassi\\n\\nTandoori Chicken, Butter Chicken, Lamb Vindaloo, Vegetable Samosas, Chicken Tikka Masala, Palak Paneer, Chana Masala, Biryani, Garlic Naan, Mango Lassi'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=SequentialChain(chains=[name_chain,food_items],\n",
    "               input_variables=['cuisine'],output_variables=['name','Menu'])\n",
    "chain.invoke({'cuisine':'Indian'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69704bed-594a-4f68-a521-8d80045a6b7f",
   "metadata": {},
   "source": [
    "#########In Langchain there are some functions like tools , agents etc as free version of Chatgpt has data upto september 2022 so for getting other information or doing mathematical operation this tools and agents are used\n",
    "i have tried tools like wikipedia,google search and llm-math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ebbd03-64e9-4dd6-a0da-8bd1c01ed95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m We can use Wikipedia to find out when Elon Musk was born and his current age.\n",
      "Action: Wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
      "Thought:\u001b[32;1m\u001b[1;3m We can use Wikipedia to find out when Elon Musk was born and his current age.\n",
      "Action: Calculator\n",
      "Action Input: 2024 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m We now know that Elon Musk will be 53 years old in 2024.\n",
      "Final Answer: Elon Musk will be 53 years old in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk will be 53 years old in 2024.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools=load_tools(['wikipedia','llm-math'],llm=llm)\n",
    "agent=initialize_agent(tools,llm,AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "agent.run(\"When was Elon musk born? what is his age in 2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae0ae8-92e8-44db-82fd-de7812108f8b",
   "metadata": {},
   "source": [
    "########For working with google api we need to create an account on serp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c79a8d0a-178d-47c8-85b3-df6d3e51e65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$27.36 trillion'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['SERPAPI_API_KEY']='Use your own SERP-API Key'\n",
    "tools=load_tools(['serpapi','llm-math'],llm=llm)\n",
    "agent=initialize_agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,Verbose=True)\n",
    "agent.run(\"what was the GDP of US in 2023 ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa41d70-6304-47c3-8d00-d8754dccae34",
   "metadata": {},
   "source": [
    "########## Here i have tried to work with memory as we have seen in chat-gpt it remembers the previous conversation which we have done so we can also do it using ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14995ee7-227d-4b1a-bc76-cdb552f96696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"El Sabor de México\"  (The Flavor of Mexico)\n"
     ]
    }
   ],
   "source": [
    "memory=ConversationBufferMemory()\n",
    "chain=LLMChain(llm=llm,prompt=name, memory=memory)\n",
    "name_1=chain.run(\"Mexican\")\n",
    "print(name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b3e149d-035b-4e4b-81b8-78790b9622cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "name_2=chain.run(\"Indian\")\n",
    "print(name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dede5e2-4f8a-47da-96f9-b316c8c8951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "\"El Sabor de México\"  (The Flavor of Mexico)\n",
      "Human: Indian\n",
      "AI: \n",
      "\n",
      "\"Spice Palace\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2736e1a-d20f-4a16-9eae-0cda5be4a177",
   "metadata": {},
   "source": [
    "######## Conversation buffer memory has some disadvantage as it grows along with the conversation endlessly which is not feasable as memory point of view as well as cost point so to overcome this disadvantage there is a library called ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7386fc-948a-4fd3-8709-a1d7ae8c88c5",
   "metadata": {},
   "source": [
    "### Model with rembering only one conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e54e1344-b57a-45d5-8c6a-25f30684d750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was won by the West Indies in 1975.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory=ConversationBufferWindowMemory(k=1)\n",
    "convo=ConversationChain(llm=OpenAI(temperature=0.6),memory=memory)\n",
    "convo.run(\"who won the first cricket world cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707dad3a-da45-4b0f-9320-4e7f516c7eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  5+5 is equal to 10.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e217a174-f0d3-417a-85f5-78be9db6e118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I cannot answer that question as I do not have enough context. Do you have a specific team or event in mind?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of wining team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51309fc-293d-4623-a59d-cf03d5e19afb",
   "metadata": {},
   "source": [
    "Model with rembering 2 conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57c3bd38-9d30-4433-9dc3-341630051cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final match by 17 runs. The tournament was held in England and was officially called the Prudential Cup. Do you have any other questions about the Cricket World Cup?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory=ConversationBufferWindowMemory(k=2)\n",
    "convo=ConversationChain(llm=OpenAI(temperature=0.6),memory=memory)\n",
    "convo.run(\"who won the first cricket world cup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6278e552-8cc5-4b8d-b979-5e89192ea5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The answer to 5+5 is 10. Would you like to know more about mathematical operations?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47498479-0d20-4feb-a612-84b399eb5aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The captain of the winning West Indies team in the first Cricket World Cup was Clive Lloyd. He was a left-handed batsman and a medium-paced bowler. He also led the West Indies to victory in the second Cricket World Cup in 1979. Do you have any other questions about the first Cricket World Cup?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the captain of wining team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa08648-0346-4805-a0f2-bc6b2c9e48fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
